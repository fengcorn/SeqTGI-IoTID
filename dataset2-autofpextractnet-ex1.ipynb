{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f9jPFY17VzGa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 导入所有必要的层\n",
    "\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow.keras.applications.mobilenet_v2\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LDohl23U_-B",
    "outputId": "872be7e5-9c12-4388-d233-2901d003c136",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sequence\n",
    "num_classes = 19\n",
    "input_shape = (5, 60, 60, 1)\n",
    "\n",
    "def split_train_and_test(x, y, test_size):\n",
    "    x_train, x_test, y_train, y_test = [], [], [], []\n",
    "    for i in range(y.max()+1):\n",
    "        all_x = x[y==i]\n",
    "        shuf = np.random.permutation(len(all_x))\n",
    "        all_x = all_x[shuf]\n",
    "        percent = int(len(all_x)*(1-test_size))\n",
    "        x_train.extend(all_x[:percent])\n",
    "        x_test.extend(all_x[percent:])\n",
    "        y_train.extend([i]*percent)\n",
    "        y_test.extend([i]*(len(all_x)-percent))\n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "x = np.load('./train_unsw_60_60.npy')\n",
    "y = np.load('./label_unsw_60_60.npy')\n",
    "x_train, x_test, y_train, y_test = split_train_and_test(x, y, test_size=0.3)\n",
    "x_raw = np.load('./train_unsw_60_60_raw.npy')\n",
    "y_raw = np.load('./train_unsw_60_60_raw.npy')\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "x_raw = x_raw.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "x_raw = np.expand_dims(x_raw, -1)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "print(x_raw.shape[0], \"raw samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "erVL7OAzXoG5",
    "outputId": "0c297287-a4f0-45ee-ecec-11c2fa12a225"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bCgVW8EXtso",
    "outputId": "4122bfe8-b0c2-48f7-ffab-c27c4866120f"
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxfefeiUaUE0"
   },
   "outputs": [],
   "source": [
    "class InvertedBottleNeckLayers(tf.keras.Model):\n",
    "    def __init__(self,in_fitler,expansion_rate,stride):\n",
    "        super(InvertedBottleNeckLayers, self).__init__()\n",
    "        #self.in_filter=in_fitler\n",
    "        self.stride=stride\n",
    "        self.expansion_rate=expansion_rate\n",
    "\n",
    "        self.conv1=layers.Conv2D(expansion_rate*in_fitler,kernel_size=[1,1],strides=[1,1],padding='same')\n",
    "        self.conv1Batch=layers.BatchNormalization()\n",
    "        self.conv1relu6=layers.Activation('relu6')\n",
    "\n",
    "        self.Dwise=layers.DepthwiseConv2D(kernel_size=[3,3],strides=stride,padding='same')\n",
    "        self.Dwisebatch=layers.BatchNormalization()\n",
    "        self.Dwiserelu6=layers.Activation('relu6')\n",
    "\n",
    "        self.conv22 = layers.Conv2D(in_fitler, kernel_size=[1, 1], strides=[1, 1], padding='same')\n",
    "        self.conv22batch = layers.BatchNormalization()\n",
    "\n",
    "    def call(self,inputs,training=None):\n",
    "        \n",
    "        if len(tf.shape(inputs)) == 5:\n",
    "            batch = tf.shape(inputs)[0]\n",
    "            height = tf.shape(inputs)[2]\n",
    "            width = tf.shape(inputs)[3]\n",
    "            channel = tf.shape(inputs)[4]\n",
    "            inputs = tf.reshape(inputs, [batch*5, height, width,channel])\n",
    "        \n",
    "        x=self.conv1(inputs)\n",
    "        x=self.conv1Batch(x)\n",
    "        x=self.conv1relu6(x)\n",
    "\n",
    "        x=self.Dwise(x)\n",
    "        x=self.Dwisebatch(x)\n",
    "        x=self.Dwiserelu6(x)\n",
    "        DwiseChannel=np.shape(x)[-1]\n",
    "        \n",
    "        conv22batch = self.conv22batch(x)\n",
    "        #如果步长为1且经过深度卷积输出的通道数和输入的通道数相同，\n",
    "        #则进行shortcut，否则直接输出\n",
    "        #conv22 = layers.Conv2D(self.in_filter, kernel_size=[1, 1], strides=[1, 1], padding='same')(x)\n",
    "        #conv22batch = layers.BatchNormalization()(conv22)\n",
    "        if self.stride==1 and DwiseChannel==np.shape(inputs)[-1]:\n",
    "            x_out=tf.add(conv22batch,inputs)\n",
    "        else:\n",
    "            x_out=conv22batch\n",
    "        #print(x_out)\n",
    "        return x_out\n",
    "\n",
    "class AutoFPExtractNet(tf.keras.Model):\n",
    "    def __init__(self,in_fitler=32,num_classes=19):\n",
    "        super(AutoFPExtractNet, self).__init__()\n",
    "        self.conv11=layers.Conv2D(in_fitler,kernel_size=[3,3],strides=[2,2],padding='same')\n",
    "        self.conv11batch=layers.BatchNormalization()\n",
    "        self.conv11relu=layers.Activation('relu6')\n",
    "\n",
    "        #self.bottleneck(t,c,n,c,i)这里的i表示第几个bottleneck\n",
    "        self.bottleneck1 = self.bottleneck(1, 16, 1, 1, 1)\n",
    "        self.bottleneck2 = self.bottleneck(1, 24, 2, 2, 2)\n",
    "        self.bottleneck3 = self.bottleneck(6, 32, 2, 2, 3)\n",
    "        self.bottleneck4 = self.bottleneck(6, 48, 3, 2, 4)\n",
    "        self.bottleneck5 = self.bottleneck(6, 64, 1, 1, 5)\n",
    "\n",
    "        self.conv22=layers.Conv2D(192,kernel_size=[1,1],strides=[1,1],padding='same')\n",
    "        self.conv22batch=layers.BatchNormalization()\n",
    "        self.conv22relu=layers.Activation('relu6')\n",
    "        \n",
    "        self.dropout=layers.Dropout(0.5)\n",
    "        self.gru=layers.GRU(64, return_sequences=False)\n",
    "        self.l2normalize=layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "\n",
    "\n",
    "    def bottleneck(self,t,c,n,s,i):\n",
    "        bottle=keras.Sequential([],name='bottleneck'+str(i))\n",
    "        bottle.add(InvertedBottleNeckLayers(c,t,stride=s))\n",
    "        for i in range(n-1):\n",
    "            bottle.add(InvertedBottleNeckLayers(c,t,1))\n",
    "        return bottle\n",
    "\n",
    "    def call(self,inputs,training=None):\n",
    "        x = self.conv11(inputs)\n",
    "        x = self.conv11batch(x)\n",
    "        x = self.conv11relu(x)\n",
    "\n",
    "        x = self.bottleneck1(x)\n",
    "        x = self.bottleneck2(x)\n",
    "        x = self.bottleneck3(x)\n",
    "        x = self.bottleneck4(x)\n",
    "        x = self.bottleneck5(x)\n",
    "        \n",
    "        x = self.conv22(x)\n",
    "        x = self.conv22batch(x)\n",
    "        x = self.conv22relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        height = tf.shape(x)[1]\n",
    "        width = tf.shape(x)[2]\n",
    "        channel = tf.shape(x)[3]\n",
    "        x = tf.reshape(x, [-1, 5, height * width * channel])\n",
    "        x = self.gru(x)\n",
    "        x = self.l2normalize(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model=AutoFPExtractNet()\n",
    "model.build(input_shape=(None, None, 60, 60, 1))\n",
    "model.call(tf.keras.layers.Input(shape=(None, 60, 60, 1),batch_size = 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCk_MMBYhBlm",
    "outputId": "5475599b-aba0-44ef-ef68-29a3f1bfb88e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNUjUZdcV1iB",
    "outputId": "0e15a1a9-c098-4dfd-bd2f-c1cdce65c801",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 200\n",
    "model.compile(loss=tfa.losses.TripletSemiHardLoss(margin=0.5), optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "# 日志记录\n",
    "csv_logger = CSVLogger('./dataset2_training_dscgru_ex1.csv',append=False)\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.predict(x_test)\n",
    "results = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/fengcorn/code/SeqTGI-IoTID/Ex2_dscgru_predict_result.npy', results)\n",
    "test_results = model.predict(x_raw)\n",
    "np.save('/home/fengcorn/code/SeqTGI-IoTID/Ex2_dscgru_predict_result_raw.npy', test_results)\n",
    "np.save('/home/fengcorn/code/SeqTGI-IoTID/Ex2_dscgru_y_raw.npy', y_raw)\n",
    "np.save('/home/fengcorn/code/SeqTGI-IoTID/Ex2_dscgru_y_train.npy', y_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
